# -*- coding: utf-8 -*-
"""TelegramSentimentalAnaylsis - Group Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19V19hlHbeQ48jTzTOC2R07TpBnN2EvCk
"""

import numpy as np
import pandas as pd 
import plotly
from plotly import graph_objs as go
import datetime

from plotly.offline import init_notebook_mode, iplot
import plotly.graph_objs as go
import plotly.express as px
import matplotlib.pyplot as plt

from plotly import tools
import seaborn as sns
init_notebook_mode(connected=True)
from itertools import zip_longest
import string 
import re

from nltk.corpus import stopwords 
from nltk.util import ngrams
#for sentiment analysis
from nltk.sentiment import SentimentIntensityAnalyzer
import nltk 
import zipfile

"""Download the specific truncated dataset here: https://www.kaggle.com/aagghh/crypto-telegram-groups?select=group_messages_binance.json

Upload the zip and extract the zip within the session:
"""

!unzip /content/expanded_dataset.zip

pd.set_option('display.max_colwidth',3000)
binance = pd.read_json('expanded_dataset/binance_1_28-3_23.json')
okex = pd.read_json('expanded_dataset/OKEx_1_28-3_23.json')
bittrex = pd.read_json('expanded_dataset/bittrex_1_28-3_23.json')
huobi = pd.read_json('expanded_dataset/huobi_1_28-3_23.json')
kucoin = pd.read_json('expanded_dataset/kucoin_1_28-3_23.json')

binance = binance['messages']
okex = okex['messages']
bittrex = bittrex['messages']
huobi = huobi['messages']
kucoin = kucoin['messages']

#Used to add sentiment data into the datasets
nltk.download('vader_lexicon')
sia = SentimentIntensityAnalyzer()

#Binance sentiment analysis
for messageInfo in binance:
  if not 'text' in messageInfo:
    continue

  if type(messageInfo['text']) is str:
    polarity_scores = sia.polarity_scores(messageInfo['text'])
  elif type(messageInfo['text']) is dict:
    polarity_scores = sia.polarity_scores(messageInfo['text']['text'])
  else:
    continue

  if (polarity_scores['neg'] > polarity_scores['neu']) and (polarity_scores['neg'] > polarity_scores['pos']):
    messageInfo['sentiment'] = 'negative'
  elif (polarity_scores['neu'] > polarity_scores['pos']) and (polarity_scores['pos'] > polarity_scores['neg']):
    messageInfo['sentiment'] = 'neutral-lean positive'
  elif (polarity_scores['pos'] == polarity_scores['neg']):
    messageInfo['sentiment'] = 'neutral'
  elif (polarity_scores['neu'] > polarity_scores['pos']):
    messageInfo['sentiment'] = 'neutral-lean negative'
  else:
    messageInfo['sentiment'] = 'positive'

#Okex sentiment analysis
for messageInfo in okex:
  if not 'text' in messageInfo:
    continue

  if type(messageInfo['text']) is str:
    polarity_scores = sia.polarity_scores(messageInfo['text'])
  elif type(messageInfo['text']) is dict:
    polarity_scores = sia.polarity_scores(messageInfo['text']['text'])
  else:
    continue

  if (polarity_scores['neg'] > polarity_scores['neu']) and (polarity_scores['neg'] > polarity_scores['pos']):
    messageInfo['sentiment'] = 'negative'
  elif (polarity_scores['neu'] > polarity_scores['pos']) and (polarity_scores['pos'] > polarity_scores['neg']):
    messageInfo['sentiment'] = 'neutral-lean positive'
  elif (polarity_scores['pos'] == polarity_scores['neg']):
    messageInfo['sentiment'] = 'neutral'
  elif (polarity_scores['neu'] > polarity_scores['pos']):
    messageInfo['sentiment'] = 'neutral-lean negative'
  else:
    messageInfo['sentiment'] = 'positive'

#Bittrex sentiment analysis
for messageInfo in bittrex:
  if not 'text' in messageInfo:
    continue

  if type(messageInfo['text']) is str:
    polarity_scores = sia.polarity_scores(messageInfo['text'])
  elif type(messageInfo['text']) is dict:
    polarity_scores = sia.polarity_scores(messageInfo['text']['text'])
  else:
    continue

  if (polarity_scores['neg'] > polarity_scores['neu']) and (polarity_scores['neg'] > polarity_scores['pos']):
    messageInfo['sentiment'] = 'negative'
  elif (polarity_scores['neu'] > polarity_scores['pos']) and (polarity_scores['pos'] > polarity_scores['neg']):
    messageInfo['sentiment'] = 'neutral-lean positive'
  elif (polarity_scores['pos'] == polarity_scores['neg']):
    messageInfo['sentiment'] = 'neutral'
  elif (polarity_scores['neu'] > polarity_scores['pos']):
    messageInfo['sentiment'] = 'neutral-lean negative'
  else:
    messageInfo['sentiment'] = 'positive'

#Huobi sentiment analysis
for messageInfo in huobi:
  if not 'text' in messageInfo:
    continue

  if type(messageInfo['text']) is str:
    polarity_scores = sia.polarity_scores(messageInfo['text'])
  elif type(messageInfo['text']) is dict:
    polarity_scores = sia.polarity_scores(messageInfo['text']['text'])
  else:
    continue

  if (polarity_scores['neg'] > polarity_scores['neu']) and (polarity_scores['neg'] > polarity_scores['pos']):
    messageInfo['sentiment'] = 'negative'
  elif (polarity_scores['neu'] > polarity_scores['pos']) and (polarity_scores['pos'] > polarity_scores['neg']):
    messageInfo['sentiment'] = 'neutral-lean positive'
  elif (polarity_scores['pos'] == polarity_scores['neg']):
    messageInfo['sentiment'] = 'neutral'
  elif (polarity_scores['neu'] > polarity_scores['pos']):
    messageInfo['sentiment'] = 'neutral-lean negative'
  else:
    messageInfo['sentiment'] = 'positive'

#Kucoin sentiment analysis
for messageInfo in kucoin:
  if not 'text' in messageInfo:
    continue

  if type(messageInfo['text']) is str:
    polarity_scores = sia.polarity_scores(messageInfo['text'])
  elif type(messageInfo['text']) is dict:
    polarity_scores = sia.polarity_scores(messageInfo['text']['text'])
  else:
    continue

  if (polarity_scores['neg'] > polarity_scores['neu']) and (polarity_scores['neg'] > polarity_scores['pos']):
    messageInfo['sentiment'] = 'negative'
  elif (polarity_scores['neu'] > polarity_scores['pos']) and (polarity_scores['pos'] > polarity_scores['neg']):
    messageInfo['sentiment'] = 'neutral-lean positive'
  elif (polarity_scores['pos'] == polarity_scores['neg']):
    messageInfo['sentiment'] = 'neutral'
  elif (polarity_scores['neu'] > polarity_scores['pos']):
    messageInfo['sentiment'] = 'neutral-lean negative'
  else:
    messageInfo['sentiment'] = 'positive'

print(binance.head())

# binance = pd.json_normalize(binance.to_dict(), record_path =['messages'])
binance = pd.json_normalize(binance)
okex = pd.json_normalize(okex)
bittrex = pd.json_normalize(bittrex)
huobi = pd.json_normalize(huobi)
kucoin = pd.json_normalize(kucoin)

binance = binance.rename(columns={'text': 'message'})
okex = okex.rename(columns={'text': 'message'})
bittrex = bittrex.rename(columns={'text': 'message'})
huobi = huobi.rename(columns={'text': 'message'})
kucoin = kucoin.rename(columns={'text': 'message'})

binance[110000:110005]

consolidated_data = huobi
consolidated_data = consolidated_data.append(okex)
consolidated_data = consolidated_data.append(bittrex)
consolidated_data = consolidated_data.append(binance)
consolidated_data = consolidated_data.append(kucoin)

import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords

#date manipulation
stopwords = stopwords.words('english')
consolidated_data['CreationDate'] = pd.to_datetime(consolidated_data['date'])
consolidated_data['CreationYear'] = consolidated_data['CreationDate'].dt.year
consolidated_data['CreationMonth'] = consolidated_data['CreationDate'].dt.month
consolidated_data['CreationMonth'] = consolidated_data['CreationMonth'].apply(lambda x : "0"+str(x) if len(str(x)) < 2 else x)
#consolidated_data['CreationDay'] = "27"
consolidated_data['CreationDay'] = consolidated_data['CreationDate'].dt.day
#consolidated_data['MessageDate'] = consolidated_data["CreationYear"].astype(str) +"-"+ consolidated_data["CreationMonth"].astype(str) +"-"+ consolidated_data["CreationDay"].astype(str)
consolidated_data['MessageDate'] = pd.to_datetime({'year' : consolidated_data["CreationYear"], 
                                                   'month' : consolidated_data["CreationMonth"], 
                                                   'day' : consolidated_data["CreationDay"]})
#Putting this here as a temp until the original graphs look right
consolidated_data['MessageDate Sentiment'] = consolidated_data["CreationYear"].astype(str) +"-"+ consolidated_data["CreationMonth"].astype(str) +"-"+ consolidated_data["CreationDate"].dt.day.astype(str)
consolidated_data['Message'] = consolidated_data['message'].fillna(" ")

## cleaning text
def clntxt(text):
    if isinstance(text, list):
      return " "
    text = text.lower()
    text = " ".join([c for c in text.split() if c not in stopwords])
    for c in string.punctuation:
        text = text.replace(c, " ")
    text = " ".join([c for c in text.split() if c not in stopwords])
    
    words = []
    ignorewords = ["www", "http","https" "com"]
    for wrd in text.split():
        if len(wrd) <= 2: 
            continue
        if wrd in ignorewords:
            continue
        words.append(wrd)
    text = " ".join(words)    
    return text

# counting mentions
def count_presence(txt, wrds):    
    cnt = 0
    txt = " "+txt+" "
    for wrd in wrds.split("|"):
        if " "+wrd+" " in txt:
            cnt += 1 
    return cnt

consolidated_data['CleanMessage'] = consolidated_data['Message'].apply(lambda x : clntxt(x))

temp = consolidated_data.groupby('MessageDate')
print(temp)

import plotly.io as pio
pio.renderers.default = 'colab'
def plotit(listed, title):    
    traces = []
    for model in listed:
        temp = consolidated_data.groupby('MessageDate').agg({model : "sum"}).reset_index()
        #temp = temp.sort_values(by=['CreationDate'])
        print(temp)
        trace = go.Scatter(x = temp["MessageDate"], y = temp[model], name=model.split("|")[0].title(), line=dict(shape="spline", width=2), mode = "lines")
        print(trace)
        traces.append(trace)

    layout = go.Layout(
        paper_bgcolor='#fff',
        plot_bgcolor="#fff",
        legend=dict(orientation="h", y=1.1),
        title=title,
        title_x=0.5,
        xaxis=dict(
            gridcolor='rgb(255,255,255)',
            showgrid=True,
            showline=False,
            showticklabels=True,
            tickcolor='rgb(127,127,127)',
            ticks='outside',
            zeroline=False
        ),
        yaxis=dict(
            title="Number of Mentions",
            gridcolor='rgb(255,255,255)',
            showgrid=False,
            showline=False,
            showticklabels=True,
            tickcolor='rgb(127,127,127)',
            ticks='outside',
            zeroline=False
        ),
    )

    fig = go.Figure(data=traces, layout=layout)
    iplot(fig)

#btc vs eth
models = ["btc", "eth"]
for col in models:
    consolidated_data[col] = consolidated_data["CleanMessage"].apply(lambda x : count_presence(x, col))
plotit(models, "Telegram Discussions: BTC vs ETH")

models = ["dot", "xrp", "ltc", "xlm"]
for col in models:
    consolidated_data[col] = consolidated_data["CleanMessage"].apply(lambda x : count_presence(x, col))
plotit(models, "Telegram Discussions: DOT vs XRP vs LTC vs XLM")

#btc vs defi
models = ["btc", "defi"]
for col in models:
    consolidated_data[col] = consolidated_data["CleanMessage"].apply(lambda x : count_presence(x, col))
plotit(models, "Telegram Discussions: BTC vs DeFi")

models = ["usdt", "dai"]
for col in models:
    consolidated_data[col] = consolidated_data["CleanMessage"].apply(lambda x : count_presence(x, col))
plotit(models, "Stable coins: USDT vs DAI")

models = ["uniswap", "sushiswap", "1inch"]
for col in models:
    consolidated_data[col] = consolidated_data["CleanMessage"].apply(lambda x : count_presence(x, col))
plotit(models, "DEX: UNISWAP vs Sushiswap vs 1inch")

#defi protocols
models = ["makerdao", "compound"]
for col in models:
    consolidated_data[col] = consolidated_data["CleanMessage"].apply(lambda x : count_presence(x, col))
plotit(models, "DeFi protocols: MakerDAO vs Compound")

import plotly.graph_objects as graphpx

#print(consolidated_data.groupby(['MessageDate', 'sentiment']).shape[0])

def plotArea(model): 
  sentiment_temp = consolidated_data.groupby(['MessageDate Sentiment', 'sentiment']).agg({model : 'sum'}).reset_index()
  neutral_sentiment = sentiment_temp[sentiment_temp['sentiment'] == 'neutral']
  neutral_pos_sentiment = sentiment_temp[sentiment_temp['sentiment'] == 'neutral-lean positive']
  neutral_neg_sentiment = sentiment_temp[sentiment_temp['sentiment'] == 'neutral-lean negative']
  positive_sentiment = sentiment_temp[sentiment_temp['sentiment'] == 'positive']
  negative_sentiment = sentiment_temp[sentiment_temp['sentiment'] == 'negative']

  sentiment_plot = graphpx.Figure()
  sentiment_plot.add_trace(go.Scatter(
      name = 'Negative Messages',
      x = negative_sentiment['MessageDate Sentiment'],
      y = negative_sentiment[model],
      stackgroup = 'one'
  ))

  sentiment_plot.add_trace(go.Scatter(
      name = 'Neutral-Lean Negative Messages',
      x = neutral_neg_sentiment['MessageDate Sentiment'],
      y = neutral_neg_sentiment[model],
      stackgroup = 'one'
  ))

  sentiment_plot.add_trace(go.Scatter(
      name = 'Neutral Messages',
      x = neutral_sentiment['MessageDate Sentiment'],
      y = neutral_sentiment[model],
      stackgroup = 'one'
  ))

  sentiment_plot.add_trace(go.Scatter(
      name = 'Neutral-Lean Positive Messages',
      x = neutral_pos_sentiment['MessageDate Sentiment'],
      y = neutral_pos_sentiment[model],
      stackgroup = 'one'
  ))

  sentiment_plot.add_trace(go.Scatter(
      name = 'Positive Messages',
      x = positive_sentiment['MessageDate Sentiment'],
      y = positive_sentiment[model],
      stackgroup = 'one'
  ))

  sentiment_plot.update_layout(
      title = "Sentiment Analysis:"+model,
      xaxis_title='Date',
      yaxis_title='Number of Messages'
  )
  sentiment_plot.show()

plotArea('btc')

plotArea('defi')

plotArea('usdt')

plotArea('dai')

plotArea('uniswap')

plotArea('sushiswap')

plotArea('1inch')

plotArea('makerdao')

plotArea('compound')

#Beginning of Polina's price analysis
btc = pd.read_csv('https://raw.githubusercontent.com/PoliNemkova/Telegram_analysis/main/Bitcoin.csv')
ltc = pd.read_csv('https://raw.githubusercontent.com/PoliNemkova/Telegram_analysis/main/Litecoin.csv')
eth = pd.read_csv('https://raw.githubusercontent.com/PoliNemkova/Telegram_analysis/main/Ethereum.csv')

btc.head(5)

btc['mean']=(btc['high'] + btc['low'])/2
btc=btc.drop(['open','close','high','low'], axis=1)

ltc['mean']=(ltc['high'] + ltc['low'])/2
ltc=ltc.drop(['open','close','high','low'], axis=1)

eth['mean']=(eth['high'] + eth['low'])/2
eth=eth.drop(['open','close','high','low'], axis=1)

eth.head(5)

x = btc['mean']
y = ltc['mean']
z = eth['mean']

plt.plot(x)
plt.plot(y, color = 'r')
plt.plot(z, color = 'b')
plt.title('Bitcoin, Litecoin, and Ethereum mean prices')
plt.ylabel('Price')
plt.xlabel('Date')

x = btc['mean']
y = ltc['mean']
z = eth['mean']


plt.plot(y, color = 'r')
plt.plot(z, color = 'b')
plt.title('Litecoin and Ethereum mean prices')
plt.ylabel('Price')
plt.xlabel('Date')

#Pearson Correlations

ltc_btc_corr = ltc['mean'].corr(btc['mean'])
ltc_eth_corr = ltc['mean'].corr(eth['mean'])
btc_eth_corr = btc['mean'].corr(eth['mean'])
print('ltc_eth_corr', ltc_eth_corr, 'STRONG (>0.8)')
print('ltc_btc_corr', ltc_btc_corr)
print('btc_eth_corrr', btc_eth_corr, 'SIGNIFICANT (>0.6)')


###PREFERABLY ADD HERE CORRELATION WITH NUMBER OF MENTIONING OF THE CORRESPONDING COIN AND I'TS PRICE

#took the data from the models above
btc_mentions = [ 150,  179,   60,  128,  104,  192,  131,  127,  178,  221,  206,  371,
                 149,  164,  189,  124,  114,  144,  192,  234,  240,  144,  256,  313,
                 200,  358, 1388, 1199, 1396, 1399, 1176, 1880, 1139, 1087, 1369, 1365,
                 989,  974,  986,  824,  822, 1020,  911,  876, 1295,  825, 1353,  895,
                 898,  764,  646,  792, 1028, 1421,  652]

eth_mentions = [ 77,  72,  57,  57,  56, 230, 180, 324, 244, 161, 142, 114,  81, 100,
                 96,  78,  81,  49, 103, 119, 109,  93, 160, 177, 123, 106, 285, 302,
                344, 283, 325, 376, 307, 243, 256, 223, 206, 361, 295, 279, 339, 281,
                303, 181, 349, 214, 198, 184, 292, 244, 302, 222, 160, 292, 267]

ltc_mentions = [  9,  20,   4,   4,  17,  35,  27,  51,  27,  11,  12,  18,  16,  16,
                  4,  19,  19,   8,   9,  20,  24,   5,  21,  14,  15,  24,  30,  78,
                 91, 100,  75,  75,  58, 101, 100, 107, 125,  54,  66, 123,  96, 119,
                 97, 215, 196, 136, 120, 137, 119,  81,  48,  64,  54, 113,  39]

btc_mentions = pd.DataFrame(btc_mentions)
eth_mentions = pd.DataFrame(eth_mentions)
ltc_mentions = pd.DataFrame(ltc_mentions)

#removing unneeded data from prices
btc_55 = btc[:54]
ltc_55 = ltc[:54]
eth_55 = eth[:54]



#plotting BTC means VS mentions
x = btc['mean']
y = btc_mentions


plt.plot(x, color = 'r')
plt.plot(y, color = 'b')
plt.title('BTC prices VS mentions in Telegram')
plt.ylabel('Price')
plt.xlabel('Date')

x = ltc['mean']
y = ltc_mentions


plt.plot(x, color = 'r')
plt.plot(y, color = 'b')
plt.title('LTC prices VS mentions in Telegram')
plt.ylabel('Price')
plt.xlabel('Date')

x = eth['mean']
y = eth_mentions


plt.plot(x, color = 'r')
plt.plot(y, color = 'b')
plt.title('ETC prices VS mentions in Telegram')
plt.ylabel('Price')
plt.xlabel('Date')

#btc_mentions = btc_mentions.stack()
#btc_mentions = btc_mentions.drop(,axis=1)
#btc_mentions.drop(columns=0, axis=1)
btc_mentions

btc_mentions

btc_55_mean.shape
print(btc_55_mean)

btc_55 = btc[:54]
btc_55_mean = btc_55['mean']
btc_55_mean.corr(btc_mentions)

btc_mentions.shape

btc.shape

btc.head(50)

